{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"authorship_tag":"ABX9TyPsXOaumACQ1jdn7Z4QQP8C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D23KLBC8VbMD","executionInfo":{"status":"ok","timestamp":1638435113398,"user_tz":-540,"elapsed":112590,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}},"outputId":"a755570d-a178-4bc7-8cd2-4cde41802b46"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnW2Nab4hQbJ","executionInfo":{"status":"ok","timestamp":1638438087686,"user_tz":-540,"elapsed":1220,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}},"outputId":"c862a4c4-1612-4aa8-e2d8-3d1802dbad86"},"source":["!pip install os"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for os\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"njGaK8yxhSW5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H1Mz1BNYV9Zk","executionInfo":{"status":"ok","timestamp":1638438080671,"user_tz":-540,"elapsed":6135,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n","import torchvision.utils as utils\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from matplotlib import pyplot as plt\n","\n","################################\n","#      Discriminator 설계      #\n","################################\n","\n","class CIFAR10_Discriminator(nn.Module):\n","\n","  def __init__(self, config):\n","    super(CIFAR10_Discriminator, self).__init__()\n","\n","    # 입력층 노드 수\n","    self.inode = config[\"d_input_node\"]\n","    # 은닉층 노드 수\n","    self.hnode = config[\"d_hidden_node\"]\n","    # 출력층 노드 수: 분류해야 하는 레이블 수\n","    self.onode = config[\"d_output_node\"]\n","\n","    # 신경망 설계\n","    self.net = nn.Sequential(nn.Linear(self.inode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.onode, bias=True),\n","                             nn.Sigmoid())\n","    \n","  def forward(self, input_features):\n","    hypothesis = self.net(input_features)\n","    return hypothesis\n","\n","################################\n","#        Generator 설계        #\n","################################\n","\n","class CIFAR10_Generator(nn.Module):\n","\n","  def __init__(self, config):\n","    super(CIFAR10_Generator, self).__init__()\n","\n","    # 입력층 노드 수\n","    self.inode = config[\"g_input_node\"]\n","    # 은닉층 노드 수\n","    self.hnode = config[\"g_hidden_node\"]\n","    # 출력층 노드 수: 생성해야 하는 노드 수\n","    self.onode = config[\"g_output_node\"]\n","\n","    # 신경망 설계\n","    self.net = nn.Sequential(nn.Linear(self.inode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.hnode, bias=True),\n","                             nn.LeakyReLU(),\n","                             nn.Dropout(0.1),\n","                             nn.Linear(self.hnode, self.onode, bias=True),\n","                             nn.Tanh())\n","\n","  def forward(self, input_features):\n","    hypothesis = self.net(input_features)\n","    return hypothesis\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IrIrDW_Wt9x","executionInfo":{"status":"ok","timestamp":1638438126747,"user_tz":-540,"elapsed":309,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}}},"source":["def load_dataset():\n","  standardizator = transforms.Compose([transforms.Scale(64), transforms.ToTensor(), transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))])\n","  train_X = datasets.CIFAR10(root='/gdrive/My Drive/colab/gan/mnist/data/', train=True, transform=standardizator, download=True)    \n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kQbGwLbZjLY","executionInfo":{"status":"ok","timestamp":1638438128228,"user_tz":-540,"elapsed":220,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}}},"source":["def imshow_grid(img): \n","    img = utils.make_grid(img.cpu().detach())\n","    img = (img+1)/2\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)))\n","    plt.show()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2mKb-n4Zlix","executionInfo":{"status":"ok","timestamp":1638438129897,"user_tz":-540,"elapsed":432,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}}},"source":["def get_noise(batch_size=64, g_input_node=100):\n","    return torch.randn(batch_size, g_input_node)\n","\n","def do_test(model, input_node):\n","  # 평가 모드 셋팅\n","  model.eval()\n","\n","  with torch.no_grad():\n","\n","    X = get_noise(g_input_node=input_node).cuda()\n","    hypothesis = model(X)\n","    hypothesis_ = hypothesis.reshape((-1,3,32,32))\n","    imshow_grid(hypothesis_)  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"6W4nmKr6Zlgs","executionInfo":{"status":"ok","timestamp":1638438131738,"user_tz":-540,"elapsed":239,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}}},"source":["# 모델 학습 함수\n","def train(config):\n","\n","  # Discriminator와 Generator 모델 생성\n","  # 이곳을 채우세요.\n","  D = CIFAR10_Discriminator(config).cuda()\n","  G = CIFAR10_Generator(config).cuda()\n","\n","  # 데이터 읽기\n","  input_features = load_dataset()\n","  \n","  # DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n","  train_dataloader = DataLoader(input_features, shuffle=True, batch_size=config[\"batch_size\"])\n","\n","  # 바이너리 크로스엔트로피 비용 함수 \n","  loss_func = nn.BCELoss()\n","\n","  # Discriminator와 Generator 옵티마이저 함수 지정\n","  # 이곳을 채우세요.\n","  D_optimizer = torch.optim.Adam(D.parameters(),lr = config[\"learn_rate\"])\n","  G_optimizer = torch.optim.Adam(G.parameters(),lr = config[\"learn_rate\"])\n","\n","\n","  for epoch in range(config[\"epoch\"]+1):\n","\n","    # Discriminator와 Generator 학습 모드 셋팅\n","    D.train()\n","    G.train()\n","    \n","    # epoch 마다 평균 비용을 저장하기 위한 리스트\n","    D_costs, G_costs = [], []\n","\n","    for (step, batch) in enumerate(train_dataloader):\n","\n","      # batch = (input_features[step], labels[step])*batch_size\n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      # 배치 크기 만큼 입력 데이터 읽기 \n","      input_features, _ = batch\n","      input_features = input_features.view(-1,config['d_input_node'])\n","      \n","      ################################\n","      #      Discriminator 학습      #\n","      ################################\n","\n","      # 역전파 변화도 초기화\n","      D_optimizer.zero_grad()\n"," \n","      # 진짜에 대한 비용 계산\n","      real_hypothesis = D(input_features)\n","      real_labels = Variable(torch.ones(config[\"batch_size\"],1)).cuda()\n","      real_cost = loss_func(real_hypothesis, real_labels)\n","      \n","      # 가짜에 대한 비용 계산\n","      fake_input_features = get_noise(config[\"batch_size\"],config[\"g_input_node\"]).cuda()\n","      fake_hypothesis = D(G(fake_input_features))\n","      fake_labels = Variable(torch.zeros(config[\"batch_size\"],1)).cuda()\n","      # 이곳을 채우세요.\n","      fake_cost = loss_func(fake_hypothesis, fake_labels)\n","\n","      # 전체 비용 역전파 수행\n","      # 이곳을 채우세요.\n","      total_cost = real_cost + fake_cost\n","      total_cost.backward()\n","      D_optimizer.step()\n","\n","      # 현재 batch의 스텝 별 Discrimnator 비용 저장\n","      D_costs.append(total_cost.data.item())\n","\n","      ################################\n","      #        Generator 학습        #\n","      ################################\n"," \n","      # 역전파 변화도 초기화\n","      G_optimizer.zero_grad()\n","\n","      # 가짜에 대한 비용 계산\n","      fake_input_features = get_noise(config[\"batch_size\"],config[\"g_input_node\"]).cuda()\n","      # 이곳을 채우세요.\n","      fake_hypothesis = D(G(fake_input_features))\n","      fake_labels = Variable(torch.ones(config[\"batch_size\"],1)).cuda()\n","      # 이곳을 채우세요.\n","      fake_cost = loss_func(fake_hypothesis, fake_labels)\n","\n","      # 가짜 생성 비용 역전파 수행\n","      fake_cost.backward()\n","      G_optimizer.step()\n","\n","      # 현재 batch의 스텝 별 Generator 비용 저장\n","      G_costs.append(fake_cost.data.item())\n","    \n","    # 10 에폭마다 중간 결과 출력 및 저장\n","    if epoch%10 == 0:\n","    \n","      # 평균 비용 출력\n","      print(\"Avg Loss D={0:f}, Avg Loss G={1:f}\".format(np.mean(D_costs), np.mean(G_costs)))\n","\n","      # Generator 저장\n","      torch.save(G.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))\n","\n","      # 생성된 샘플 출력\n","      do_test(G,config['g_input_node'])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"c8uQKzsEZleb","executionInfo":{"status":"error","timestamp":1638438679989,"user_tz":-540,"elapsed":1144,"user":{"displayName":"ber hana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsJnXHLE8u40vToUZtylANXypVFTPdHnXlw7A9=s64","userId":"05240663579252203348"}},"outputId":"dbc04db4-17f9-4bab-d24d-7bb22b8c2fbc"},"source":["import os\n","if(__name__==\"__main__\"):\n","\n","    root_dir = \"/gdrive/My Drive/colab/gan/cifar10\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"model_name\":\"epoch_{0:d}.pt\".format(10),\n","              \"root_dir\":root_dir,\n","              \"output_dir\":output_dir,\n","              \"d_input_node\":3072,\n","              \"d_hidden_node\":256,\n","              \"d_output_node\":1,\n","              \"g_input_node\":100,\n","              \"g_hidden_node\":256,\n","              \"g_output_node\":3072,\n","              \"learn_rate\":0.0002,\n","              \"batch_size\":100,\n","              \"epoch\":10,\n","              }\n","\n","    train(config)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:317: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n","  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-2fc3bfad8636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m               }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-9eb5d1726369>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# 바이너리 크로스엔트로피 비용 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     99\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","metadata":{"id":"X0fFW-kAhXG1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgSOmyqdgaqN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0azY7PamZlPI"},"source":[""],"execution_count":null,"outputs":[]}]}